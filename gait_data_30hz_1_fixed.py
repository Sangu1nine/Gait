"""
ë³´í–‰ ë° ë‚™ìƒ ê°ì§€ IMU ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œê·¸ë¨ (100Hz ì„¼ì„œ, ë‹¤ìš´ìƒ˜í”Œë§)
MODIFIED 2025-01-30: ë‚™ìƒ ê°ì§€ìš© 100Hz ì„¼ì„œ ìˆ˜ì§‘, ë³´í–‰ ê°ì§€ìš© 30Hz ë‹¤ìš´ìƒ˜í”Œë§
Features:
- 100Hz IMU ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ (ë©€í‹°ìŠ¤ë ˆë“œ)
- ì‹¤ì‹œê°„ ë‚™ìƒ ê°ì§€ (TensorFlow Lite) - 100Hz ë°ì´í„° ì‚¬ìš©
- ì‹¤ì‹œê°„ ë³´í–‰ ê°ì§€ (TensorFlow Lite) - 30Hz ë‹¤ìš´ìƒ˜í”Œë§ ë°ì´í„° ì‚¬ìš©
- Supabase ì§ì ‘ ì—…ë¡œë“œ
"""

from smbus2 import SMBus
from bitstring import Bits
import os
from dotenv import load_dotenv
import time
import datetime
import numpy as np
import threading
import pickle
from collections import deque
import tensorflow as tf
from supabase import create_client, Client
import io
import csv

# Global variables
bus = SMBus(1)
DEV_ADDR = 0x68

# IMU register addresses
register_gyro_xout_h = 0x43
register_gyro_yout_h = 0x45
register_gyro_zout_h = 0x47
sensitive_gyro = 131.0

register_accel_xout_h = 0x3B
register_accel_yout_h = 0x3D
register_accel_zout_h = 0x3F
sensitive_accel = 16384.0

# Model paths
GAIT_MODEL_PATH = "models/gait_detection/model.tflite"
FALL_MODEL_PATH = "models/fall_detection/fall_detection.tflite"
GAIT_SCALER_PATH = "scalers/gait_detection"
FALL_SCALER_PATH = "scalers/fall_detection"

# Detection parameters
GAIT_WINDOW_SIZE = 60  # Window size for gait detection model
FALL_WINDOW_SIZE = 150  # Window size for fall detection model
SENSOR_HZ = 100  # ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ ì£¼íŒŒìˆ˜ (100Hz)
GAIT_TARGET_HZ = 30   # ë³´í–‰ ê°ì§€ìš© ë‹¤ìš´ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ (30Hz)
GAIT_THRESHOLD = 0.24  # Gait detection threshold
FALL_THRESHOLD = 0.5  # Fall detection threshold

# State transition parameters
GAIT_TRANSITION_FRAMES = 60  # 2 seconds at 30Hz
MIN_GAIT_DURATION_FRAMES = 300  # 10 seconds at 30Hz

# Detection timing parameters - ëª©ì ë³„ ìµœì í™”
FALL_DETECTION_INTERVAL = 0.05  # ë‚™ìƒ ê°ì§€ ì£¼ê¸° (0.05ì´ˆ = 20Hz) - ì‹¤ì‹œê°„ì„± ê°•í™”
GAIT_DETECTION_INTERVAL = 0.1   # ë³´í–‰ ê°ì§€ ì£¼ê¸° (0.1ì´ˆ = 10Hz) - ì •í™•ë„ ìš°ì„ , ë°°ì¹˜ ì²˜ë¦¬
GAIT_STRIDE = 1  # ë³´í–‰ ê°ì§€ stride (1 = ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬)
GAIT_BATCH_SIZE = 5  # ë³´í–‰ ê°ì§€ì‹œ í•œë²ˆì— ì²˜ë¦¬í•  ìœˆë„ìš° ìˆ˜ (ì •í™•ë„ í–¥ìƒ)

# Global Supabase client variable
supabase = None

# Global variables for sensor data collection
sensor_data_lock = threading.Lock()
raw_sensor_buffer = deque(maxlen=max(GAIT_WINDOW_SIZE * 4, FALL_WINDOW_SIZE * 2))  # 100Hz ë²„í¼ í¬ê¸° ì¡°ì •
gait_downsampled_buffer = deque(maxlen=GAIT_WINDOW_SIZE * 3)  # 30Hz ë‹¤ìš´ìƒ˜í”Œë§ëœ ë°ì´í„° ë²„í¼
is_running = False

# Gait detection variables - ê°œì„ ëœ êµ¬ì¡°
gait_interpreter = None
gait_scaler = None
gait_label_encoder = None
gait_state = "non-gait"
gait_consecutive_count = 0  # ì—°ì†ëœ gait ì˜ˆì¸¡ ìˆ˜
non_gait_consecutive_count = 0  # ì—°ì†ëœ non-gait ì˜ˆì¸¡ ìˆ˜
current_gait_data = deque()  # dequeë¡œ ë³€ê²½í•˜ì—¬ íš¨ìœ¨ì„± í–¥ìƒ
current_gait_start_time = None
last_prediction_frame = -1  # ë§ˆì§€ë§‰ ì˜ˆì¸¡ëœ í”„ë ˆì„ ë²ˆí˜¸

# Fall detection variables
fall_interpreter = None
fall_scalers = {}  # Dictionary for multiple scalers

def read_data(register):
    """Read data from IMU register"""
    high = bus.read_byte_data(DEV_ADDR, register)
    low = bus.read_byte_data(DEV_ADDR, register+1)
    val = (high << 8) + low
    return val

def twocomplements(val):
    """Convert 2's complement"""
    s = Bits(uint=val, length=16)
    return s.int

def gyro_dps(val):
    """Convert gyroscope value to degrees/second"""
    return twocomplements(val)/sensitive_gyro

def accel_ms2(val):
    """Convert acceleration value to m/sÂ²"""
    return (twocomplements(val)/sensitive_accel) * 9.80665

def init_supabase():
    """Initialize Supabase client with detailed debugging"""
    global supabase
    try:
        print("ğŸ” Supabase ì´ˆê¸°í™” ì‹œì‘...")
        
        # .env íŒŒì¼ ì¡´ì¬ í™•ì¸
        env_path = ".env"
        if os.path.exists(env_path):
            print(f"âœ… .env íŒŒì¼ ë°œê²¬: {os.path.abspath(env_path)}")
        else:
            print(f"âš ï¸ .env íŒŒì¼ì´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì—†ìŠµë‹ˆë‹¤: {os.path.abspath(env_path)}")
            print(f"   í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
            print(f"   ë””ë ‰í† ë¦¬ ë‚´ìš©: {os.listdir('.')}")
        
        # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
        load_dotenv()
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")
        
        # í™˜ê²½ë³€ìˆ˜ ë””ë²„ê¹… ì •ë³´
        print(f"ğŸ”— SUPABASE_URL: {'âœ… ë¡œë“œë¨' if url else 'âŒ ì—†ìŒ'}")
        if url:
            print(f"   URL: {url}")
        print(f"ğŸ”‘ SUPABASE_KEY: {'âœ… ë¡œë“œë¨' if key else 'âŒ ì—†ìŒ'}")
        if key:
            print(f"   Key prefix: {key[:20]}...")
        
        if not url or not key:
            print("âŒ í™˜ê²½ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            print("   1. .env íŒŒì¼ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€")
            print("   2. .env íŒŒì¼ì— SUPABASE_URL=your_url í˜•ì‹ìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆëŠ”ì§€")
            print("   3. .env íŒŒì¼ì— SUPABASE_KEY=your_key í˜•ì‹ìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆëŠ”ì§€")
            raise RuntimeError("Supabase í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ (SUPABASE_URL ë˜ëŠ” SUPABASE_KEY)")
        
        print("ğŸ”„ Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...")
        supabase = create_client(url, key)
        print("âœ… Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì„±ê³µ")
        
        # ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸
        print("ğŸŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        import requests
        try:
            response = requests.get(f"{url}/rest/v1/", headers={"apikey": key}, timeout=10)
            print(f"âœ… ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì„±ê³µ (HTTP {response.status_code})")
        except requests.exceptions.ConnectionError:
            print("âŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨ - ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”")
            return False
        except requests.exceptions.Timeout:
            print("âŒ ì—°ê²° ì‹œê°„ ì´ˆê³¼ - ë„¤íŠ¸ì›Œí¬ê°€ ëŠë¦¬ê±°ë‚˜ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤")
            return False
        except Exception as net_error:
            print(f"âš ï¸ ë„¤íŠ¸ì›Œí¬ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {net_error}")
        
        # Supabase ì¸ì¦ í…ŒìŠ¤íŠ¸
        print("ğŸ” Supabase ì¸ì¦ í…ŒìŠ¤íŠ¸ ì¤‘...")
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
            response = supabase.table('fall_history').select('count').limit(1).execute()
            print("âœ… Supabase ì¸ì¦ ì„±ê³µ!")
            print("âœ… Supabase ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as auth_error:
            print(f"âŒ Supabase ì¸ì¦ ì‹¤íŒ¨: {auth_error}")
            print("   ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            print("   1. API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€")
            print("   2. í”„ë¡œì íŠ¸ URLì´ ì •í™•í•œì§€")
            print("   3. fall_history í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€")
            print("   4. API í‚¤ì— í•´ë‹¹ í…Œì´ë¸” ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€")
            return False
            
    except Exception as e:
        print(f"âŒ Supabase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        return False

def load_models():
    """Load gait and fall detection models with version compatibility"""
    global gait_interpreter, gait_scaler, gait_label_encoder, fall_interpreter, fall_scalers
    
    # Check scikit-learn version
    try:
        import sklearn
        print(f"ğŸ“¦ scikit-learn version: {sklearn.__version__}")
    except ImportError:
        print("âŒ scikit-learn not installed")
    
    # Load gait detection model
    try:
        if os.path.exists(GAIT_MODEL_PATH):
            gait_interpreter = tf.lite.Interpreter(model_path=GAIT_MODEL_PATH)
            gait_interpreter.allocate_tensors()
            print(f"âœ… Gait model loaded: {GAIT_MODEL_PATH}")
        
        # Load gait scaler with version compatibility
        gait_scaler_file = os.path.join(GAIT_SCALER_PATH, "standard_scaler.pkl")
        if os.path.exists(gait_scaler_file):
            try:
                import warnings
                with warnings.catch_warnings():
                    warnings.filterwarnings("ignore", category=UserWarning)
                    with open(gait_scaler_file, 'rb') as f:
                        gait_scaler = pickle.load(f)
                print(f"âœ… Gait StandardScaler loaded (version compatibility handled)")
            except Exception as scaler_error:
                print(f"âš ï¸ Gait StandardScaler loading failed: {scaler_error}")
                print("   Continuing without gait scaler - manual scaling may be needed")
                gait_scaler = None
        
        # Load gait label encoder with version compatibility
        gait_label_encoder_file = os.path.join(GAIT_SCALER_PATH, "label_encoder.pkl")
        if os.path.exists(gait_label_encoder_file):
            try:
                import warnings
                with warnings.catch_warnings():
                    warnings.filterwarnings("ignore", category=UserWarning)
                    with open(gait_label_encoder_file, 'rb') as f:
                        gait_label_encoder = pickle.load(f)
                print(f"âœ… Gait LabelEncoder loaded (version compatibility handled)")
            except Exception as encoder_error:
                print(f"âš ï¸ Gait LabelEncoder loading failed: {encoder_error}")
                print("   Continuing without gait label encoder - prediction results will be numeric")
                gait_label_encoder = None
        else:
            print(f"âš ï¸ Gait LabelEncoder file not found: {gait_label_encoder_file}")
            gait_label_encoder = None
            
    except Exception as e:
        print(f"âŒ Gait model loading error: {e}")
    
    # Load fall detection model
    try:
        if os.path.exists(FALL_MODEL_PATH):
            fall_interpreter = tf.lite.Interpreter(model_path=FALL_MODEL_PATH)
            fall_interpreter.allocate_tensors()
            print(f"âœ… Fall model loaded: {FALL_MODEL_PATH}")
        
        # Load fall scalers (both minmax and standard) with version compatibility
        scalers_loaded = 0
        total_scalers = 0
        
        for sensor in ['AccX', 'AccY', 'AccZ', 'GyrX', 'GyrY', 'GyrZ']:
            minmax_file = os.path.join(FALL_SCALER_PATH, f"{sensor}_minmax_scaler.pkl")
            standard_file = os.path.join(FALL_SCALER_PATH, f"{sensor}_standard_scaler.pkl")
            
            # Load MinMax scaler
            if os.path.exists(minmax_file):
                total_scalers += 1
                try:
                    import warnings
                    with warnings.catch_warnings():
                        warnings.filterwarnings("ignore", category=UserWarning)
                        with open(minmax_file, 'rb') as f:
                            fall_scalers[f"{sensor}_minmax"] = pickle.load(f)
                    scalers_loaded += 1
                except Exception as e:
                    print(f"âš ï¸ Failed to load {sensor}_minmax scaler: {e}")
            
            # Load Standard scaler
            if os.path.exists(standard_file):
                total_scalers += 1
                try:
                    import warnings
                    with warnings.catch_warnings():
                        warnings.filterwarnings("ignore", category=UserWarning)
                        with open(standard_file, 'rb') as f:
                            fall_scalers[f"{sensor}_standard"] = pickle.load(f)
                    scalers_loaded += 1
                except Exception as e:
                    print(f"âš ï¸ Failed to load {sensor}_standard scaler: {e}")
        
        print(f"âœ… Fall scalers loaded: {scalers_loaded}/{total_scalers}")
        
        if scalers_loaded == 0:
            print("âš ï¸ No fall scalers loaded - fall detection may not work correctly")
        elif scalers_loaded < total_scalers:
            print("âš ï¸ Some fall scalers failed to load - fall detection accuracy may be reduced")
            
    except Exception as e:
        print(f"âŒ Fall model loading error: {e}")

def sensor_collection_thread():
    """Thread for collecting sensor data at 100Hz"""
    global raw_sensor_buffer, gait_downsampled_buffer, is_running
    
    start_time = time.time()
    frame_count = 0
    gait_frame_count = 0
    last_gait_sample_time = 0
    gait_sampling_interval = 1.0 / GAIT_TARGET_HZ  # 30Hzë¥¼ ìœ„í•œ ìƒ˜í”Œë§ ê°„ê²©
    
    while is_running:
        try:
            # Read IMU sensor data
            accel_x = accel_ms2(read_data(register_accel_xout_h))
            accel_y = -accel_ms2(read_data(register_accel_yout_h))
            accel_z = accel_ms2(read_data(register_accel_zout_h))
            
            gyro_x = gyro_dps(read_data(register_gyro_xout_h))
            gyro_y = gyro_dps(read_data(register_gyro_yout_h))
            gyro_z = gyro_dps(read_data(register_gyro_zout_h))
            
            # Calculate timestamp
            current_time = time.time()
            sync_timestamp = current_time - start_time
            
            # Store raw sensor data (100Hz) for fall detection
            sensor_data = {
                'frame': frame_count,
                'sync_timestamp': sync_timestamp,
                'accel_x': accel_x,
                'accel_y': accel_y,
                'accel_z': accel_z,
                'gyro_x': gyro_x,
                'gyro_y': gyro_y,
                'gyro_z': gyro_z,
                'unix_timestamp': current_time
            }
            
            with sensor_data_lock:
                # 100Hz ë²„í¼ì— ì¶”ê°€ (ë‚™ìƒ ê°ì§€ìš©)
                if len(raw_sensor_buffer) >= raw_sensor_buffer.maxlen:
                    raw_sensor_buffer.popleft()
                raw_sensor_buffer.append(sensor_data)
                
                # 30Hz ë‹¤ìš´ìƒ˜í”Œë§ (ë³´í–‰ ê°ì§€ìš©)
                if sync_timestamp - last_gait_sample_time >= gait_sampling_interval:
                    gait_sensor_data = sensor_data.copy()
                    gait_sensor_data['gait_frame'] = gait_frame_count
                    
                    if len(gait_downsampled_buffer) >= gait_downsampled_buffer.maxlen:
                        gait_downsampled_buffer.popleft()
                    gait_downsampled_buffer.append(gait_sensor_data)
                    
                    last_gait_sample_time = sync_timestamp
                    gait_frame_count += 1
            
            frame_count += 1
            
            # Maintain 100Hz sampling rate
            next_sample_time = start_time + (frame_count * (1.0 / SENSOR_HZ))
            sleep_time = next_sample_time - time.time()
            
            if sleep_time > 0:
                time.sleep(sleep_time)
                
        except Exception as e:
            print(f"âŒ Sensor collection error: {e}")
            time.sleep(0.001)

def preprocess_for_gait(sensor_window):
    """Preprocess sensor data for gait detection"""
    if not gait_scaler:
        return None
    
    try:
        # Extract sensor values in correct order
        sensor_array = np.array([[
            data['accel_x'], data['accel_y'], data['accel_z'],
            data['gyro_x'], data['gyro_y'], data['gyro_z']
        ] for data in sensor_window], dtype=np.float32)
        
        # Reshape for scaler
        sensor_array = sensor_array.reshape(1, GAIT_WINDOW_SIZE, 6)
        n_samples, n_frames, n_features = sensor_array.shape
        sensor_reshaped = sensor_array.reshape(-1, n_features)
        
        # Apply Standard scaling
        sensor_scaled = gait_scaler.transform(sensor_reshaped)
        sensor_scaled = sensor_scaled.reshape(n_samples, n_frames, n_features).astype(np.float32)
        
        return sensor_scaled
    except Exception as e:
        print(f"âŒ Gait preprocessing error: {e}")
        return None

def preprocess_for_fall(sensor_window):
    """Preprocess sensor data for fall detection"""
    if not fall_scalers:
        return None
    
    try:
        # Process each sensor channel
        processed_data = []
        
        for data in sensor_window:
            # Apply transformations for fall detection
            acc_x = data['accel_x'] / 9.80665
            acc_y = data['accel_y'] / 9.80665  # Sign change
            acc_z = data['accel_z'] / 9.80665
            gyr_x = data['gyro_x']
            gyr_y = data['gyro_y']
            gyr_z = data['gyro_z']
            
            processed_data.append([acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z])
        
        # Convert to numpy array
        sensor_array = np.array(processed_data, dtype=np.float32)
        
        # Apply scalers for each sensor channel
        sensor_names = ['AccX', 'AccY', 'AccZ', 'GyrX', 'GyrY', 'GyrZ']
        scaled_data = np.zeros_like(sensor_array)
        
        for i, sensor_name in enumerate(sensor_names):
            # Apply MinMax scaler first if available
            if f"{sensor_name}_minmax" in fall_scalers:
                scaled_data[:, i] = fall_scalers[f"{sensor_name}_minmax"].transform(
                    sensor_array[:, i].reshape(-1, 1)
                ).flatten()
            else:
                scaled_data[:, i] = sensor_array[:, i]
            
            # Apply Standard scaler after MinMax if available
            if f"{sensor_name}_standard" in fall_scalers:
                scaled_data[:, i] = fall_scalers[f"{sensor_name}_standard"].transform(
                    scaled_data[:, i].reshape(-1, 1)
                ).flatten()
        
        return scaled_data.reshape(1, FALL_WINDOW_SIZE, 6)
    except Exception as e:
        print(f"âŒ Fall preprocessing error: {e}")
        return None

def gait_detection_thread():
    """Thread for gait detection using 30Hz downsampled data with batch processing for accuracy"""
    global gait_state, gait_consecutive_count, non_gait_consecutive_count
    global current_gait_data, current_gait_start_time, last_prediction_frame
    
    print("ğŸš¶ Gait detection thread initialized (30Hz downsampled, batch processing for accuracy)")
    
    while is_running:
        try:
            # Get available downsampled sensor data (30Hz)
            with sensor_data_lock:
                if len(gait_downsampled_buffer) < GAIT_WINDOW_SIZE + GAIT_BATCH_SIZE:
                    time.sleep(0.01)
                    continue
                
                # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ìœˆë„ìš° ì¤€ë¹„
                buffer_list = list(gait_downsampled_buffer)
                available_frames = len(buffer_list)
            
            # ë°°ì¹˜ ì²˜ë¦¬: stride=1ë¡œ ì—¬ëŸ¬ ìœˆë„ìš° ìƒì„±
            windows_to_process = []
            frame_numbers = []
            
            # ë§ˆì§€ë§‰ ì²˜ë¦¬ëœ í”„ë ˆì„ ì´í›„ë¶€í„° ì²˜ë¦¬
            start_idx = max(0, available_frames - GAIT_WINDOW_SIZE - GAIT_BATCH_SIZE + 1)
            
            for i in range(GAIT_BATCH_SIZE):
                window_start = start_idx + i * GAIT_STRIDE
                window_end = window_start + GAIT_WINDOW_SIZE
                
                if window_end <= available_frames:
                    window = buffer_list[window_start:window_end]
                    current_frame = window[-1]['gait_frame']
                    
                    # ì´ë¯¸ ì²˜ë¦¬ëœ í”„ë ˆì„ì€ ê±´ë„ˆë›°ê¸°
                    if current_frame > last_prediction_frame:
                        windows_to_process.append(window)
                        frame_numbers.append(current_frame)
            
            # ë°°ì¹˜ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
            if windows_to_process and gait_interpreter and gait_scaler:
                batch_predictions = []
                
                for window in windows_to_process:
                    preprocessed = preprocess_for_gait(window)
                    if preprocessed is not None:
                        # Run inference
                        input_details = gait_interpreter.get_input_details()
                        output_details = gait_interpreter.get_output_details()
                        
                        gait_interpreter.set_tensor(input_details[0]['index'], preprocessed)
                        gait_interpreter.invoke()
                        
                        prediction = gait_interpreter.get_tensor(output_details[0]['index'])
                        gait_probability = prediction[0][0] if len(prediction[0]) == 1 else prediction[0][1]
                        batch_predictions.append((gait_probability, window[-1]))
                
                # ë°°ì¹˜ ê²°ê³¼ë¥¼ í‰ê· ë‚´ì–´ ë” ì•ˆì •ì ì¸ ì˜ˆì¸¡ (ì •í™•ë„ í–¥ìƒ)
                if batch_predictions:
                    avg_probability = np.mean([pred[0] for pred in batch_predictions])
                    latest_sensor_data = batch_predictions[-1][1]  # ê°€ì¥ ìµœì‹  ë°ì´í„° ì‚¬ìš©
                    
                    # Label decoding for better debugging
                    if gait_label_encoder:
                        binary_pred = 1 if avg_probability > GAIT_THRESHOLD else 0
                        try:
                            predicted_label = gait_label_encoder.inverse_transform([binary_pred])[0]
                            # Debug information with label
                            current_frame = latest_sensor_data['gait_frame']
                            if current_frame % 30 == 0:  # Print every 1 second at 30Hz
                                print(f"ğŸ” Frame {current_frame}: Batch Avg Prob={avg_probability:.3f}, Pred={predicted_label} (batch size: {len(batch_predictions)})")
                        except Exception as e:
                            print(f"âš ï¸ Label decoding failed: {e}")
                    
                    # Update consecutive counts using averaged probability
                    if avg_probability > GAIT_THRESHOLD:
                        gait_consecutive_count += len(batch_predictions)  # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ì¦ê°€
                        non_gait_consecutive_count = 0
                    else:
                        non_gait_consecutive_count += len(batch_predictions)  # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ì¦ê°€
                        gait_consecutive_count = 0
                    
                    # State transition logic
                    update_gait_state_accurate(latest_sensor_data, avg_probability, len(batch_predictions))
                    
                    # ë§ˆì§€ë§‰ ì²˜ë¦¬ëœ í”„ë ˆì„ ì—…ë°ì´íŠ¸
                    last_prediction_frame = frame_numbers[-1]
            
            time.sleep(GAIT_DETECTION_INTERVAL)  # ì •í™•ë„ ìš°ì„  ë³´í–‰ ê°ì§€ ì£¼ê¸°
            
        except Exception as e:
            print(f"âŒ Gait detection error: {e}")
            time.sleep(0.1)

def update_gait_state_accurate(latest_sensor_data, avg_probability, batch_size):
    """ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ë°°ì¹˜ ê¸°ë°˜ ë³´í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    global gait_state, current_gait_data, current_gait_start_time
    
    if gait_state == "non-gait":
        # Gait ì‹œì‘ ì¡°ê±´: ë°°ì¹˜ í‰ê·  í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ë” ì•ˆì •ì ì¸ íŒë‹¨
        adjusted_threshold_frames = GAIT_TRANSITION_FRAMES // batch_size  # ë°°ì¹˜ í¬ê¸° ê³ ë ¤í•œ ì„ê³„ê°’ ì¡°ì •
        if gait_consecutive_count >= adjusted_threshold_frames:
            gait_state = "gait"
            current_gait_start_time = latest_sensor_data['unix_timestamp']
            current_gait_data = deque()  # ìƒˆë¡œìš´ gait ë°ì´í„° ì‹œì‘
            
            # Show label-decoded result
            label_info = ""
            if gait_label_encoder:
                try:
                    predicted_label = gait_label_encoder.inverse_transform([1])[0]  # 1 = gait
                    label_info = f" -> {predicted_label}"
                except:
                    pass
            
            print(f"ğŸš¶ Gait started at gait_frame {latest_sensor_data['gait_frame']} (avg prob: {avg_probability:.3f}, batch confidence: {gait_consecutive_count}/{adjusted_threshold_frames}){label_info}")
    
    elif gait_state == "gait":
        # ë³´í–‰ ì¤‘ì¸ ê²½ìš° ë°ì´í„° ìˆ˜ì§‘ (ë°°ì¹˜ì˜ ëª¨ë“  í”„ë ˆì„ ì¶”ê°€í•˜ì§€ ì•Šê³  ìµœì‹  ë°ì´í„°ë§Œ)
        current_gait_data.append(latest_sensor_data)
        
        # Gait ì¢…ë£Œ ì¡°ê±´: ë°°ì¹˜ í‰ê·  í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ë” ì•ˆì •ì ì¸ íŒë‹¨
        adjusted_threshold_frames = GAIT_TRANSITION_FRAMES // batch_size  # ë°°ì¹˜ í¬ê¸° ê³ ë ¤í•œ ì„ê³„ê°’ ì¡°ì •
        if non_gait_consecutive_count >= adjusted_threshold_frames:
            # ë³´í–‰ ë°ì´í„° ì €ì¥ ì²´í¬
            gait_duration_frames = len(current_gait_data)
            gait_duration_seconds = gait_duration_frames / GAIT_TARGET_HZ
            
            # Show label-decoded result
            label_info = ""
            if gait_label_encoder:
                try:
                    predicted_label = gait_label_encoder.inverse_transform([0])[0]  # 0 = non-gait
                    label_info = f" -> {predicted_label}"
                except:
                    pass
            
            print(f"ğŸ›‘ Gait ended at gait_frame {latest_sensor_data['gait_frame']} (avg prob: {avg_probability:.3f}, duration: {gait_duration_frames} frames, {gait_duration_seconds:.1f}s){label_info}")
            
            if gait_duration_frames >= MIN_GAIT_DURATION_FRAMES:
                save_gait_data_to_supabase(list(current_gait_data))
                print(f"âœ… Gait data saved ({gait_duration_frames} frames)")
            else:
                print(f"âš ï¸ Gait duration too short: {gait_duration_frames} frames ({gait_duration_seconds:.1f}s < {MIN_GAIT_DURATION_FRAMES/GAIT_TARGET_HZ:.1f}s)")
            
            # ìƒíƒœ ë¦¬ì…‹
            gait_state = "non-gait"
            current_gait_data = deque()
            current_gait_start_time = None

def update_gait_state_simple(latest_sensor_data, gait_probability):
    """ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ì¸ ë³´í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸ (30Hz ê¸°ì¤€)"""
    global gait_state, current_gait_data, current_gait_start_time
    
    if gait_state == "non-gait":
        # Gait ì‹œì‘ ì¡°ê±´: ì—°ì†ìœ¼ë¡œ GAIT_TRANSITION_FRAMES ë§Œí¼ gaitë¡œ ì˜ˆì¸¡ë¨
        if gait_consecutive_count >= GAIT_TRANSITION_FRAMES:
            gait_state = "gait"
            current_gait_start_time = latest_sensor_data['unix_timestamp']
            current_gait_data = deque()  # ìƒˆë¡œìš´ gait ë°ì´í„° ì‹œì‘
            
            # Show label-decoded result
            label_info = ""
            if gait_label_encoder:
                try:
                    predicted_label = gait_label_encoder.inverse_transform([1])[0]  # 1 = gait
                    label_info = f" -> {predicted_label}"
                except:
                    pass
            
            print(f"ğŸš¶ Gait started at gait_frame {latest_sensor_data['gait_frame']} (confidence: {gait_consecutive_count}/{GAIT_TRANSITION_FRAMES}){label_info}")
    
    elif gait_state == "gait":
        # ë³´í–‰ ì¤‘ì¸ ê²½ìš° ë°ì´í„° ìˆ˜ì§‘
        current_gait_data.append(latest_sensor_data)
        
        # Gait ì¢…ë£Œ ì¡°ê±´: ì—°ì†ìœ¼ë¡œ GAIT_TRANSITION_FRAMES ë§Œí¼ non-gaitë¡œ ì˜ˆì¸¡ë¨
        if non_gait_consecutive_count >= GAIT_TRANSITION_FRAMES:
            # ë³´í–‰ ë°ì´í„° ì €ì¥ ì²´í¬
            gait_duration_frames = len(current_gait_data)
            gait_duration_seconds = gait_duration_frames / GAIT_TARGET_HZ
            
            # Show label-decoded result
            label_info = ""
            if gait_label_encoder:
                try:
                    predicted_label = gait_label_encoder.inverse_transform([0])[0]  # 0 = non-gait
                    label_info = f" -> {predicted_label}"
                except:
                    pass
            
            print(f"ğŸ›‘ Gait ended at gait_frame {latest_sensor_data['gait_frame']} (duration: {gait_duration_frames} frames, {gait_duration_seconds:.1f}s){label_info}")
            
            if gait_duration_frames >= MIN_GAIT_DURATION_FRAMES:
                save_gait_data_to_supabase(list(current_gait_data))
                print(f"âœ… Gait data saved ({gait_duration_frames} frames)")
            else:
                print(f"âš ï¸ Gait duration too short: {gait_duration_frames} frames ({gait_duration_seconds:.1f}s < {MIN_GAIT_DURATION_FRAMES/GAIT_TARGET_HZ:.1f}s)")
            
            # ìƒíƒœ ë¦¬ì…‹
            gait_state = "non-gait"
            current_gait_data = deque()
            current_gait_start_time = None

def fall_detection_thread():
    """Thread for fall detection using 100Hz data with longer interval"""
    print("ğŸš¨ Fall detection thread initialized (100Hz data, 0.2s interval)")
    
    while is_running:
        try:
            with sensor_data_lock:
                if len(raw_sensor_buffer) >= FALL_WINDOW_SIZE:
                    sensor_window = list(raw_sensor_buffer)[-FALL_WINDOW_SIZE:]
                else:
                    time.sleep(0.1)
                    continue
            
            # Preprocess and predict
            if fall_interpreter and fall_scalers:
                preprocessed = preprocess_for_fall(sensor_window)
                if preprocessed is not None:
                    # Run inference
                    input_details = fall_interpreter.get_input_details()
                    output_details = fall_interpreter.get_output_details()
                    
                    fall_interpreter.set_tensor(input_details[0]['index'], preprocessed)
                    fall_interpreter.invoke()
                    
                    prediction = fall_interpreter.get_tensor(output_details[0]['index'])
                    fall_probability = prediction[0][0] if len(prediction[0]) == 1 else prediction[0][1]
                    
                    # Check for fall
                    if fall_probability > FALL_THRESHOLD:
                        print(f"ğŸš¨ Fall detected! Probability: {fall_probability:.2f}")
                        save_fall_event_to_supabase(sensor_window[-1]['unix_timestamp'])
            
            time.sleep(FALL_DETECTION_INTERVAL)  # ë” ê¸´ ê°„ê²©ìœ¼ë¡œ ë‚™ìƒ ê°ì§€ (0.2ì´ˆ = 5Hz)
            
        except Exception as e:
            print(f"âŒ Fall detection error: {e}")
            time.sleep(0.1)

def save_gait_data_to_supabase(gait_data):
    """Save gait data as CSV to Supabase (30Hz downsampled data)"""
    if not supabase:
        print("âŒ Supabase not initialized")
        return
    
    try:
        # Create CSV in memory
        output = io.StringIO()
        writer = csv.writer(output)
        
        # Write header
        writer.writerow(['gait_frame', 'sync_timestamp', 'accel_x', 'accel_y', 'accel_z', 
                        'gyro_x', 'gyro_y', 'gyro_z'])
        
        # Write data with proper formatting
        first_timestamp = gait_data[0]['sync_timestamp']
        for data in gait_data:
            writer.writerow([
                data['gait_frame'],
                f"{data['sync_timestamp'] - first_timestamp:.6f}",  # Relative timestamp from 0
                f"{data['accel_x']:.3f}",
                f"{data['accel_y']:.3f}",
                f"{data['accel_z']:.3f}",
                f"{data['gyro_x']:.5f}",
                f"{data['gyro_y']:.5f}",
                f"{data['gyro_z']:.5f}"
            ])
        
        # Generate filename with timestamp
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"gait_data_30hz_{timestamp}.csv"
        
        # Convert to bytes
        csv_content = output.getvalue()
        csv_bytes = csv_content.encode('utf-8')
        
        # Upload to Supabase Storage with retry mechanism
        max_retries = 3
        retry_delay = 1  # seconds
        
        for attempt in range(max_retries):
            try:
                response = supabase.storage.from_('gait-data').upload(
                    file=csv_bytes,
                    path=filename,
                    file_options={"content-type": "text/csv"}
                )
                print(f"âœ… Gait data saved: {filename} ({len(gait_data)} frames)")
                return
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ Upload attempt {attempt + 1} failed: {e}. Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    raise e
        
    except Exception as e:
        print(f"âŒ Failed to save gait data: {e}")
        # Save to local file as backup
        try:
            backup_filename = f"backup_{filename}"
            with open(backup_filename, 'w') as f:
                f.write(csv_content)
            print(f"âœ… Backup saved to local file: {backup_filename}")
        except Exception as backup_e:
            print(f"âŒ Failed to save backup: {backup_e}")

def save_fall_event_to_supabase(timestamp):
    """Save fall event to Supabase database"""
    if not supabase:
        print("âŒ Supabase not initialized")
        return
    
    try:
        # Insert fall event into Fall History table
        data = {
            'timestamp': datetime.datetime.fromtimestamp(timestamp).isoformat(),
            'detected_at': datetime.datetime.now().isoformat()
        }
        
        response = supabase.table('fall_history').insert(data).execute()
        print(f"âœ… Fall event saved to database")
        
    except Exception as e:
        print(f"âŒ Failed to save fall event: {e}")

def main():
    """Main execution function"""
    global is_running
    
    print("=" * 70)
    print("ğŸš¶ Gait & Fall Detection System (Optimized for Different Priorities)")
    print("=" * 70)
    print(f"ğŸ“Š Sensor collection: {SENSOR_HZ}Hz")
    print(f"ğŸš¶ Gait detection: {GAIT_TARGET_HZ}Hz (accuracy priority - batch processing)")
    print(f"   â””â”€ Batch size: {GAIT_BATCH_SIZE}, Stride: {GAIT_STRIDE}, Interval: {GAIT_DETECTION_INTERVAL}s")
    print(f"ğŸš¨ Fall detection: {SENSOR_HZ}Hz (real-time priority)")
    print(f"   â””â”€ Interval: {FALL_DETECTION_INTERVAL}s ({1/FALL_DETECTION_INTERVAL:.0f}Hz detection)")
    print("=" * 70)
    
    # Initialize Supabase
    if not init_supabase():
        print("âš ï¸ Continuing without Supabase - data will be saved locally only")
        print("âš ï¸ Please check your SUPABASE_URL and SUPABASE_KEY in .env file")
    
    # Load models
    load_models()
    
    # Initialize IMU sensor
    bus.write_byte_data(DEV_ADDR, 0x6B, 0b00000000)
    print("âœ… IMU sensor initialized")
    
    # Start threads
    is_running = True
    
    sensor_thread = threading.Thread(target=sensor_collection_thread)
    sensor_thread.daemon = True
    sensor_thread.start()
    print("âœ… Sensor collection thread started (100Hz)")
    
    gait_thread = threading.Thread(target=gait_detection_thread)
    gait_thread.daemon = True
    gait_thread.start()
    print("âœ… Gait detection thread started (30Hz downsampled)")
    
    fall_thread = threading.Thread(target=fall_detection_thread)
    fall_thread.daemon = True
    fall_thread.start()
    print("âœ… Fall detection thread started (100Hz, 0.2s interval)")
    
    print("\nPress Ctrl+C to stop\n")
    
    try:
        while True:
            time.sleep(1)
            
            # Print status every 5 seconds
            if int(time.time()) % 5 == 0:
                with sensor_data_lock:
                    raw_buffer_size = len(raw_sensor_buffer)
                    gait_buffer_size = len(gait_downsampled_buffer)
                
                gait_data_size = len(current_gait_data) if current_gait_data else 0
                
                print(f"ğŸ“Š Status - Raw(100Hz): {raw_buffer_size}, Gait(30Hz): {gait_buffer_size}, "
                      f"State: {gait_state}, Gait count: +{gait_consecutive_count}/-{non_gait_consecutive_count}, "
                      f"Gait frames: {gait_data_size}, Last gait frame: {last_prediction_frame}")
                
    except KeyboardInterrupt:
        print("\nğŸ›‘ Stopping system...")
        
    finally:
        is_running = False
        time.sleep(1)  # Allow threads to finish
        
        # Save any remaining gait data
        if gait_state == "gait" and current_gait_data:
            gait_duration_frames = len(current_gait_data)
            print(f"ğŸ’¾ Saving remaining gait data: {gait_duration_frames} frames")
            if gait_duration_frames >= MIN_GAIT_DURATION_FRAMES:
                save_gait_data_to_supabase(list(current_gait_data))
                print(f"âœ… Final gait data saved ({gait_duration_frames} frames)")
            else:
                print(f"âš ï¸ Final gait data too short: {gait_duration_frames} frames")
        
        bus.close()
        print("âœ… System stopped")

if __name__ == "__main__":
    main() 