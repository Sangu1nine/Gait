import os
import numpy as np
import pandas as pd
from scipy import signal
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import pickle
from datetime import datetime
import glob
import json
import warnings

# NumPy 1.23.5, Pandas 1.5.3 í˜¸í™˜ì„±ì„ ìœ„í•œ ì„¤ì •
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)

class GaitDataPreprocessor:
    def __init__(self, base_path="/content/drive/MyDrive/KFall_dataset/data/gait_data"):
        self.base_path = base_path
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ë²„í„°ì›ŒìŠ¤ í•„í„° ì„¤ì • (4ì°¨, 10Hz ë¡œìš°íŒ¨ìŠ¤)
        self.fs = 30  # ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ 30Hz
        self.cutoff = 10  # ì»·ì˜¤í”„ ì£¼íŒŒìˆ˜ 10Hz
        self.order = 4
        
        # ìŠ¤ì¼€ì¼ëŸ¬
        self.minmax_scaler = MinMaxScaler()
        self.standard_scaler = StandardScaler()
        
        # ê²½ë¡œ í™•ì¸ ë° ì¶œë ¥
        print(f"ğŸ“ Base path: {self.base_path}")
        print(f"ğŸ“ Walking data path: {os.path.join(self.base_path, 'walking_data')}")
        print(f"ğŸ“ Non-walking data path: {os.path.join(self.base_path, 'Selected_non_30hz')}")
        print(f"ğŸ“ Label data path: {os.path.join(self.base_path, 'support_label_data')}")
        
    def butter_lowpass_filter(self, data):
        """ë²„í„°ì›ŒìŠ¤ ë¡œìš°íŒ¨ìŠ¤ í•„í„° ì ìš©"""
        nyq = 0.5 * self.fs
        normal_cutoff = self.cutoff / nyq
        b, a = signal.butter(self.order, normal_cutoff, btype='low', analog=False)
        # SciPy 1.10.1 í˜¸í™˜ì„±: axis ë§¤ê°œë³€ìˆ˜ ëª…ì‹œì  ì§€ì •
        filtered_data = signal.filtfilt(b, a, data, axis=0)
        return filtered_data
    
    def load_walking_data(self):
        """walking_data ë¡œë“œ (SA01~SA04)"""
        walking_data = []
        walking_labels = []
        walking_subjects = []
        
        print("\nğŸš¶ Walking ë°ì´í„° ë¡œë”© ì¤‘...")
        
        for subj in range(1, 5):  # SA01~SA04
            subj_path = os.path.join(self.base_path, f"walking_data/SA{subj:02d}")
            print(f"  ğŸ“‚ {subj_path} í™•ì¸ ì¤‘...")
            
            if not os.path.exists(subj_path):
                print(f"    âŒ ê²½ë¡œ ì—†ìŒ: {subj_path}")
                continue
                
            csv_files = glob.glob(os.path.join(subj_path, "S*.csv"))
            print(f"    ğŸ“„ {len(csv_files)}ê°œ CSV íŒŒì¼ ë°œê²¬")
            
            file_count = 0
            for csv_file in csv_files:
                try:
                    # ì„¼ì„œ ë°ì´í„° ë¡œë“œ - Pandas 1.5.3 í˜¸í™˜ì„± ê°œì„ 
                    try:
                        df = pd.read_csv(csv_file)
                    except Exception:
                        # ê¸°ë³¸ ë°©ì‹ ì‹¤íŒ¨ì‹œ python ì—”ì§„ìœ¼ë¡œ ì¬ì‹œë„
                        df = pd.read_csv(csv_file, engine='python')
                        
                    sensor_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']
                    
                    # ì„¼ì„œ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
                    missing_cols = [col for col in sensor_cols if col not in df.columns]
                    if missing_cols:
                        print(f"    âš ï¸  {os.path.basename(csv_file)}: ì„¼ì„œ ì»¬ëŸ¼ ëˆ„ë½ {missing_cols}")
                        continue
                        
                    # NumPy 1.23.5 í˜¸í™˜ì„±: ì•ˆì „í•œ ë°°ì—´ ìƒì„±
                    sensor_data = np.array(df[sensor_cols].values, dtype=np.float64)
                    
                    # ë¼ë²¨ ë°ì´í„° ë¡œë“œ
                    filename = os.path.basename(csv_file).replace('.csv', '')
                    label_file = os.path.join(self.base_path, f"support_label_data/SA{subj:02d}/{filename}_support_labels.csv")
                    
                    if os.path.exists(label_file):
                        try:
                            label_df = pd.read_csv(label_file)
                        except Exception:
                            label_df = pd.read_csv(label_file, engine='python')
                        
                        # í”„ë ˆì„ë³„ ë¼ë²¨ ìƒì„± - NumPy 1.23.5 í˜¸í™˜ì„±
                        frame_labels = np.full(len(sensor_data), 'non_gait', dtype='U50')
                        
                        for _, row in label_df.iterrows():
                            start = int(row['start_frame']) - 1  # 0-indexed
                            end = int(row['end_frame'])
                            if start >= 0 and end <= len(sensor_data):
                                frame_labels[start:end] = str(row['phase'])
                        
                        walking_data.append(sensor_data)
                        walking_labels.append(frame_labels)
                        walking_subjects.append(f"SA{subj:02d}")
                        file_count += 1
                        
                    else:
                        print(f"    âš ï¸  ë¼ë²¨ íŒŒì¼ ì—†ìŒ: {label_file}")
                        
                except Exception as e:
                    print(f"    âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {os.path.basename(csv_file)}: {str(e)}")
                    
            print(f"    âœ… SA{subj:02d}: {file_count}ê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
                    
        print(f"ğŸš¶ ì´ {len(walking_data)}ê°œ walking íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        return walking_data, walking_labels, walking_subjects
    
    def load_non_walking_data(self):
        """non-walking ë°ì´í„° ë¡œë“œ (SA06~SA38, SA34 ì œì™¸)"""
        non_walking_data = []
        non_walking_subjects = []
        
        print("\nğŸƒ Non-walking ë°ì´í„° ë¡œë”© ì¤‘...")
        
        total_files = 0
        for subj in range(6, 39):
            if subj == 34:  # SA34 ì œì™¸
                continue
                
            subj_path = os.path.join(self.base_path, f"Selected_non_30hz/SA{subj:02d}")
            
            if not os.path.exists(subj_path):
                print(f"  âŒ ê²½ë¡œ ì—†ìŒ: {subj_path}")
                continue
                
            csv_files = glob.glob(os.path.join(subj_path, "S*.csv"))
            file_count = 0
            
            for csv_file in csv_files:
                try:
                    # ì„¼ì„œ ë°ì´í„° ë¡œë“œ - Pandas 1.5.3 í˜¸í™˜ì„± ê°œì„ 
                    try:
                        df = pd.read_csv(csv_file)
                    except Exception:
                        df = pd.read_csv(csv_file, engine='python')
                        
                    sensor_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']
                    
                    # ì„¼ì„œ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
                    missing_cols = [col for col in sensor_cols if col not in df.columns]
                    if missing_cols:
                        print(f"    âš ï¸  {os.path.basename(csv_file)}: ì„¼ì„œ ì»¬ëŸ¼ ëˆ„ë½ {missing_cols}")
                        continue
                        
                    # NumPy 1.23.5 í˜¸í™˜ì„±: ì•ˆì „í•œ ë°°ì—´ ìƒì„±
                    sensor_data = np.array(df[sensor_cols].values, dtype=np.float64)
                    
                    non_walking_data.append(sensor_data)
                    non_walking_subjects.append(f"SA{subj:02d}")
                    file_count += 1
                    
                except Exception as e:
                    print(f"    âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {os.path.basename(csv_file)}: {str(e)}")
                    
            if file_count > 0:
                print(f"  âœ… SA{subj:02d}: {file_count}ê°œ íŒŒì¼ ë¡œë“œ")
            total_files += file_count
                
        print(f"ğŸƒ ì´ {len(non_walking_data)}ê°œ non-walking íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        return non_walking_data, non_walking_subjects
    
    def apply_filtering(self, data_list):
        """ëª¨ë“  ë°ì´í„°ì— ë²„í„°ì›ŒìŠ¤ í•„í„° ì ìš©"""
        if not data_list:
            print("âš ï¸  í•„í„°ë§í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
        filtered_data = []
        for i, data in enumerate(data_list):
            if i % 100 == 0:  # ì§„í–‰ë¥  í‘œì‹œ
                print(f"  ğŸ“Š í•„í„°ë§ ì§„í–‰ë¥ : {i+1}/{len(data_list)}")
                
            # NumPy 1.23.5 í˜¸í™˜ì„±: zeros_like ì‚¬ìš©
            filtered = np.zeros_like(data, dtype=np.float64)
            for j in range(data.shape[1]):  # ê° ì±„ë„ë³„ë¡œ í•„í„° ì ìš©
                filtered[:, j] = self.butter_lowpass_filter(data[:, j])
            filtered_data.append(filtered)
        return filtered_data
    
    def create_stage1_windows(self, data_list, labels_list=None):
        """Stage1ìš© ìœˆë„ìš° ìƒì„± (60 frames, stride 30)"""
        window_size = 60
        stride = 30
        
        windows = []
        window_labels = []
        
        if not data_list:
            print("âš ï¸  ìœˆë„ìš° ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            # NumPy 1.23.5 í˜¸í™˜ì„±: empty ë°°ì—´ ìƒì„±
            return np.empty((0, window_size, 6), dtype=np.float64), np.empty(0, dtype='U20')
        
        for idx, data in enumerate(data_list):
            n_frames = len(data)
            
            for start in range(0, n_frames - window_size + 1, stride):
                end = start + window_size
                windows.append(data[start:end])
                
                if labels_list is not None:
                    # Stage1: gait/non_gait ì´ì§„ ë¶„ë¥˜
                    window_label_seq = labels_list[idx][start:end]
                    # DS, SSR, SSL, double_support, single_support_left, single_support_rightì€ ëª¨ë‘ gaitë¡œ ë³€í™˜
                    binary_labels = ['gait' if l in ['DS', 'SSR', 'SSL', 'double_support', 'single_support_left', 'single_support_right'] else 'non_gait' 
                                   for l in window_label_seq]
                    # ìœˆë„ìš°ì˜ ëŒ€í‘œ ë¼ë²¨ (ë‹¤ìˆ˜ê²°)
                    unique, counts = np.unique(binary_labels, return_counts=True)
                    majority_label = unique[np.argmax(counts)]
                    window_labels.append(majority_label)
                else:
                    # non-walking ë°ì´í„°ëŠ” ëª¨ë‘ non_gait
                    window_labels.append('non_gait')
                    
        if windows:
            # NumPy 1.23.5 í˜¸í™˜ì„±: array ì‚¬ìš©ìœ¼ë¡œ ì•ˆì „í•œ ë°°ì—´ ìƒì„±
            return np.array(windows, dtype=np.float64), np.array(window_labels, dtype='U20')
        else:
            return np.empty((0, window_size, 6), dtype=np.float64), np.empty(0, dtype='U20')
    
    def create_stage2_windows(self, data_list, labels_list, subjects_list):
        """Stage2ìš© ìœˆë„ìš° ìƒì„± (15 frames, stride 1)"""
        window_size = 15
        stride = 1
        
        windows = []
        window_labels = []
        window_subjects = []
        
        if not data_list:
            print("âš ï¸  Stage2 ìœˆë„ìš° ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            # NumPy 1.23.5 í˜¸í™˜ì„±: empty ë°°ì—´ ìƒì„±
            return np.empty((0, window_size, 6), dtype=np.float64), [], np.empty(0, dtype='U20')
        
        for idx, data in enumerate(data_list):
            n_frames = len(data)
            subject_id = subjects_list[idx]
            
            # ì²˜ìŒê³¼ ë 15í”„ë ˆì„ ì œì™¸
            for start in range(15, n_frames - window_size - 14, stride):
                end = start + window_size
                windows.append(data[start:end])
                window_subjects.append(subject_id)
                
                # ê° í”„ë ˆì„ì˜ ë¼ë²¨ (DS, SSR, SSLë§Œ)
                frame_labels = []
                for frame_idx in range(start, end):
                    label = labels_list[idx][frame_idx]
                    if label in ['DS', 'SSR', 'SSL', 'double_support', 'single_support_left', 'single_support_right']:
                        # ë¼ë²¨ëª… ì •ê·œí™”
                        if label in ['double_support', 'DS']:
                            frame_labels.append('DS')
                        elif label in ['single_support_left', 'SSL']:
                            frame_labels.append('SSL')
                        elif label in ['single_support_right', 'SSR']:
                            frame_labels.append('SSR')
                        else:
                            frame_labels.append(label)
                    else:
                        frame_labels.append('DS')  # ê¸°ë³¸ê°’
                
                window_labels.append(frame_labels)
                
        if windows:
            # NumPy 1.23.5 í˜¸í™˜ì„±: array ì‚¬ìš©ìœ¼ë¡œ ì•ˆì „í•œ ë°°ì—´ ìƒì„±
            return np.array(windows, dtype=np.float64), window_labels, np.array(window_subjects, dtype='U20')
        else:
            return np.empty((0, window_size, 6), dtype=np.float64), [], np.empty(0, dtype='U20')

    def process_and_save(self):
        """ì „ì²´ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸš€ ë°ì´í„° ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (NumPy 1.23.5 í˜¸í™˜)")
        print("=" * 60)
        
        # 1. ë°ì´í„° ë¡œë“œ
        walking_data, walking_labels, walking_subjects = self.load_walking_data()
        non_walking_data, non_walking_subjects = self.load_non_walking_data()
        
        print(f"\nğŸ“Š ë°ì´í„° ë¡œë“œ ê²°ê³¼:")
        print(f"  ğŸš¶ Walking ë°ì´í„°: {len(walking_data)}ê°œ íŒŒì¼")
        print(f"  ğŸƒ Non-walking ë°ì´í„°: {len(non_walking_data)}ê°œ íŒŒì¼")
        
        # ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì˜¤ë¥˜
        if len(walking_data) == 0 and len(non_walking_data) == 0:
            raise ValueError("âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # 2. ë²„í„°ì›ŒìŠ¤ í•„í„° ì ìš©
        print(f"\nğŸ”§ ë²„í„°ì›ŒìŠ¤ í•„í„° ì ìš© ì¤‘...")
        if walking_data:
            walking_data = self.apply_filtering(walking_data)
            print(f"  âœ… Walking ë°ì´í„° í•„í„°ë§ ì™„ë£Œ")
        if non_walking_data:
            non_walking_data = self.apply_filtering(non_walking_data)
            print(f"  âœ… Non-walking ë°ì´í„° í•„í„°ë§ ì™„ë£Œ")
        
        # 3. Stage1 ë°ì´í„° ìƒì„±
        print(f"\nğŸ“¦ Stage1 ìœˆë„ìš° ìƒì„± ì¤‘...")
        walking_windows_s1, walking_labels_s1 = self.create_stage1_windows(walking_data, walking_labels)
        non_walking_windows_s1, non_walking_labels_s1 = self.create_stage1_windows(non_walking_data)
        
        print(f"  ğŸš¶ Walking windows: {walking_windows_s1.shape}")
        print(f"  ğŸƒ Non-walking windows: {non_walking_windows_s1.shape}")
        
        # ì „ì²´ Stage1 ë°ì´í„° ê²°í•© (ë¹ˆ ë°°ì—´ ì²˜ë¦¬)
        if walking_windows_s1.size > 0 and non_walking_windows_s1.size > 0:
            all_windows_s1 = np.vstack([walking_windows_s1, non_walking_windows_s1])
            all_labels_s1 = np.concatenate([walking_labels_s1, non_walking_labels_s1])
        elif walking_windows_s1.size > 0:
            all_windows_s1 = walking_windows_s1
            all_labels_s1 = walking_labels_s1
        elif non_walking_windows_s1.size > 0:
            all_windows_s1 = non_walking_windows_s1
            all_labels_s1 = non_walking_labels_s1
        else:
            raise ValueError("âŒ ìƒì„±ëœ ìœˆë„ìš°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"  ğŸ“¦ ì „ì²´ Stage1 windows: {all_windows_s1.shape}")
        
        # 4. ìŠ¤ì¼€ì¼ë§ (Stage1) - Scikit-learn 1.3.2 í˜¸í™˜ì„±
        print(f"\nâš–ï¸  Stage1 ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì¤‘...")
        # Reshape for scaling
        n_samples, n_frames, n_features = all_windows_s1.shape
        all_windows_s1_reshaped = all_windows_s1.reshape(-1, n_features)
        
        # Fit and transform
        all_windows_s1_minmax = self.minmax_scaler.fit_transform(all_windows_s1_reshaped)
        all_windows_s1_standard = self.standard_scaler.fit_transform(all_windows_s1_reshaped)
        
        # Reshape back
        all_windows_s1_minmax = all_windows_s1_minmax.reshape(n_samples, n_frames, n_features)
        all_windows_s1_standard = all_windows_s1_standard.reshape(n_samples, n_frames, n_features)
        
        print(f"  âœ… ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: MinMax, Standard")
        
        # 5. Stage2 ë°ì´í„° ìƒì„± (walking dataë§Œ)
        print(f"\nğŸ“¦ Stage2 ìœˆë„ìš° ìƒì„± ì¤‘...")
        if walking_data:
            walking_windows_s2, walking_labels_s2, walking_subjects_s2 = self.create_stage2_windows(walking_data, walking_labels, walking_subjects)
            print(f"  ğŸ“¦ Stage2 windows: {walking_windows_s2.shape}")
            print(f"  ğŸ“¦ Stage2 subjects: {walking_subjects_s2.shape}")
        else:
            # NumPy 1.23.5 í˜¸í™˜ì„±: empty ë°°ì—´ ìƒì„±
            walking_windows_s2 = np.empty((0, 15, 6), dtype=np.float64)
            walking_labels_s2 = []
            walking_subjects_s2 = np.empty(0, dtype='U20')
            print(f"  âš ï¸  Walking ë°ì´í„°ê°€ ì—†ì–´ Stage2 ìœˆë„ìš° ìƒì„± ë¶ˆê°€")
        
        # 6. ì €ì¥
        save_dir = os.path.join(self.base_path, f"preprocessed_{self.timestamp}")
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘: {save_dir}")
        
        # Stage1 ë°ì´í„° ì €ì¥ - NumPy 1.23.5 í˜¸í™˜ì„±
        np.save(os.path.join(save_dir, "stage1_data_minmax.npy"), all_windows_s1_minmax)
        np.save(os.path.join(save_dir, "stage1_data_standard.npy"), all_windows_s1_standard)
        np.save(os.path.join(save_dir, "stage1_labels.npy"), all_labels_s1)
        
        # Stage2 ë°ì´í„° ì €ì¥
        if walking_windows_s2.size > 0:
            np.save(os.path.join(save_dir, "stage2_data.npy"), walking_windows_s2)
            # Stage2 ë¼ë²¨ì€ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ pickle ì‚¬ìš©
            with open(os.path.join(save_dir, "stage2_labels.pkl"), 'wb') as f:
                pickle.dump(walking_labels_s2, f)
            np.save(os.path.join(save_dir, "stage2_subjects.npy"), walking_subjects_s2)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        with open(os.path.join(save_dir, "minmax_scaler.pkl"), 'wb') as f:
            pickle.dump(self.minmax_scaler, f)
        with open(os.path.join(save_dir, "standard_scaler.pkl"), 'wb') as f:
            pickle.dump(self.standard_scaler, f)
            
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'timestamp': self.timestamp,
            'numpy_version': np.__version__,
            'pandas_version': pd.__version__,
            'sklearn_version': '1.3.2',  # ì„¤ì¹˜ëœ ë²„ì „
            'scipy_version': '1.10.1',   # ì„¤ì¹˜ëœ ë²„ì „
            'n_walking_subjects': len(set(walking_subjects)) if walking_subjects else 0,
            'n_non_walking_subjects': len(set(non_walking_subjects)) if non_walking_subjects else 0,
            'stage1_shape': list(all_windows_s1_minmax.shape),
            'stage2_shape': list(walking_windows_s2.shape),
            'walking_subjects': list(set(walking_subjects)) if walking_subjects else [],
            'non_walking_subjects': list(set(non_walking_subjects)) if non_walking_subjects else [],
            'stage1_label_distribution': {str(label): int(count) for label, count in zip(*np.unique(all_labels_s1, return_counts=True))},
            'total_files_processed': {
                'walking': len(walking_data),
                'non_walking': len(non_walking_data)
            }
        }
        
        with open(os.path.join(save_dir, "metadata.pkl"), 'wb') as f:
            pickle.dump(metadata, f)
        
        # ë©”íƒ€ë°ì´í„°ë¥¼ JSONìœ¼ë¡œë„ ì €ì¥ (ê°€ë…ì„±ì„ ìœ„í•´)
        with open(os.path.join(save_dir, "metadata.json"), 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print("=" * 60)
        print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! (NumPy 1.23.5 í˜¸í™˜)")
        print("=" * 60)
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"  ğŸ“¦ Stage1 ë°ì´í„°: {all_windows_s1_minmax.shape}")
        print(f"  ğŸ“¦ Stage2 ë°ì´í„°: {walking_windows_s2.shape}")
        print(f"  ğŸ“‹ ë¼ë²¨ ë¶„í¬: {metadata['stage1_label_distribution']}")
        print(f"  ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {save_dir}")
        print(f"  ğŸ”¢ NumPy ë²„ì „: {np.__version__}")
        print(f"  ğŸ“Š Pandas ë²„ì „: {pd.__version__}")
        print("=" * 60)
        
        return save_dir

if __name__ == "__main__":
    preprocessor = GaitDataPreprocessor(base_path=r"C:\Walk_Test")
    preprocessor.process_and_save()