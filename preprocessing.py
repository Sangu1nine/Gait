import os
import numpy as np
import pandas as pd
from scipy import signal
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import pickle
from datetime import datetime
import glob
import json

class GaitDataPreprocessor:
    def __init__(self, base_path="/content/drive/MyDrive/KFall_dataset/data/gait_data"):
        self.base_path = base_path
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ë²„í„°ì›ŒìŠ¤ í•„í„° ì„¤ì • (4ì°¨, 10Hz ë¡œìš°íŒ¨ìŠ¤)
        self.fs = 30  # ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ 30Hz
        self.cutoff = 10  # ì»·ì˜¤í”„ ì£¼íŒŒìˆ˜ 10Hz
        self.order = 4
        
        # ìŠ¤ì¼€ì¼ëŸ¬
        self.minmax_scaler = MinMaxScaler()
        self.standard_scaler = StandardScaler()
        
        # ê²½ë¡œ í™•ì¸ ë° ì¶œë ¥
        print(f"ğŸ“ Base path: {self.base_path}")
        print(f"ğŸ“ Walking data path: {os.path.join(self.base_path, 'walking_data')}")
        print(f"ğŸ“ Non-walking data path: {os.path.join(self.base_path, 'Selected_non_30hz')}")
        print(f"ğŸ“ Label data path: {os.path.join(self.base_path, 'support_label_data')}")
        
    def butter_lowpass_filter(self, data):
        """ë²„í„°ì›ŒìŠ¤ ë¡œìš°íŒ¨ìŠ¤ í•„í„° ì ìš©"""
        nyq = 0.5 * self.fs
        normal_cutoff = self.cutoff / nyq
        b, a = signal.butter(self.order, normal_cutoff, btype='low', analog=False)
        filtered_data = signal.filtfilt(b, a, data, axis=0)
        return filtered_data
    
    def load_walking_data(self):
        """walking_data ë¡œë“œ (SA01~SA04)"""
        walking_data = []
        walking_labels = []
        walking_subjects = []
        
        print("\nğŸš¶ Walking ë°ì´í„° ë¡œë”© ì¤‘...")
        
        for subj in range(1, 5):  # SA01~SA04
            subj_path = os.path.join(self.base_path, f"walking_data/SA{subj:02d}")
            print(f"  ğŸ“‚ {subj_path} í™•ì¸ ì¤‘...")
            
            if not os.path.exists(subj_path):
                print(f"    âŒ ê²½ë¡œ ì—†ìŒ: {subj_path}")
                continue
                
            csv_files = glob.glob(os.path.join(subj_path, "S*.csv"))
            print(f"    ğŸ“„ {len(csv_files)}ê°œ CSV íŒŒì¼ ë°œê²¬")
            
            file_count = 0
            for csv_file in csv_files:
                try:
                    # ì„¼ì„œ ë°ì´í„° ë¡œë“œ
                    df = pd.read_csv(csv_file)
                    sensor_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']
                    
                    # ì„¼ì„œ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
                    missing_cols = [col for col in sensor_cols if col not in df.columns]
                    if missing_cols:
                        print(f"    âš ï¸  {os.path.basename(csv_file)}: ì„¼ì„œ ì»¬ëŸ¼ ëˆ„ë½ {missing_cols}")
                        continue
                        
                    sensor_data = df[sensor_cols].values
                    
                    # ë¼ë²¨ ë°ì´í„° ë¡œë“œ
                    filename = os.path.basename(csv_file).replace('.csv', '')
                    label_file = os.path.join(self.base_path, f"support_label_data/SA{subj:02d}/{filename}_support_labels.csv")
                    
                    if os.path.exists(label_file):
                        label_df = pd.read_csv(label_file)
                        
                        # í”„ë ˆì„ë³„ ë¼ë²¨ ìƒì„±
                        frame_labels = np.full(len(sensor_data), 'non_gait', dtype=object)
                        
                        for _, row in label_df.iterrows():
                            start = int(row['start_frame']) - 1  # 0-indexed
                            end = int(row['end_frame'])
                            if start >= 0 and end <= len(sensor_data):
                                frame_labels[start:end] = row['phase']
                        
                        walking_data.append(sensor_data)
                        walking_labels.append(frame_labels)
                        walking_subjects.append(f"SA{subj:02d}")
                        file_count += 1
                        
                    else:
                        print(f"    âš ï¸  ë¼ë²¨ íŒŒì¼ ì—†ìŒ: {label_file}")
                        
                except Exception as e:
                    print(f"    âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {os.path.basename(csv_file)}: {str(e)}")
                    
            print(f"    âœ… SA{subj:02d}: {file_count}ê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
                    
        print(f"ğŸš¶ ì´ {len(walking_data)}ê°œ walking íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        return walking_data, walking_labels, walking_subjects
    
    def load_non_walking_data(self):
        """non-walking ë°ì´í„° ë¡œë“œ (SA06~SA38, SA34 ì œì™¸)"""
        non_walking_data = []
        non_walking_subjects = []
        
        print("\nğŸƒ Non-walking ë°ì´í„° ë¡œë”© ì¤‘...")
        
        total_files = 0
        for subj in range(6, 39):
            if subj == 34:  # SA34 ì œì™¸
                continue
                
            subj_path = os.path.join(self.base_path, f"Selected_non_30hz/SA{subj:02d}")
            
            if not os.path.exists(subj_path):
                print(f"  âŒ ê²½ë¡œ ì—†ìŒ: {subj_path}")
                continue
                
            csv_files = glob.glob(os.path.join(subj_path, "S*.csv"))
            file_count = 0
            
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    sensor_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']
                    
                    # ì„¼ì„œ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
                    missing_cols = [col for col in sensor_cols if col not in df.columns]
                    if missing_cols:
                        print(f"    âš ï¸  {os.path.basename(csv_file)}: ì„¼ì„œ ì»¬ëŸ¼ ëˆ„ë½ {missing_cols}")
                        continue
                        
                    sensor_data = df[sensor_cols].values
                    
                    non_walking_data.append(sensor_data)
                    non_walking_subjects.append(f"SA{subj:02d}")
                    file_count += 1
                    
                except Exception as e:
                    print(f"    âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {os.path.basename(csv_file)}: {str(e)}")
                    
            if file_count > 0:
                print(f"  âœ… SA{subj:02d}: {file_count}ê°œ íŒŒì¼ ë¡œë“œ")
            total_files += file_count
                
        print(f"ğŸƒ ì´ {len(non_walking_data)}ê°œ non-walking íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        return non_walking_data, non_walking_subjects
    
    def apply_filtering(self, data_list):
        """ëª¨ë“  ë°ì´í„°ì— ë²„í„°ì›ŒìŠ¤ í•„í„° ì ìš©"""
        if not data_list:
            print("âš ï¸  í•„í„°ë§í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
        filtered_data = []
        for i, data in enumerate(data_list):
            if i % 100 == 0:  # ì§„í–‰ë¥  í‘œì‹œ
                print(f"  ğŸ“Š í•„í„°ë§ ì§„í–‰ë¥ : {i+1}/{len(data_list)}")
                
            filtered = np.zeros_like(data)
            for j in range(data.shape[1]):  # ê° ì±„ë„ë³„ë¡œ í•„í„° ì ìš©
                filtered[:, j] = self.butter_lowpass_filter(data[:, j])
            filtered_data.append(filtered)
        return filtered_data
    
    def create_stage1_windows(self, data_list, labels_list=None):
        """Stage1ìš© ìœˆë„ìš° ìƒì„± (60 frames, stride 30)"""
        window_size = 60
        stride = 30
        
        windows = []
        window_labels = []
        
        if not data_list:
            print("âš ï¸  ìœˆë„ìš° ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return np.array([]).reshape(0, window_size, 6), np.array([])
        
        for idx, data in enumerate(data_list):
            n_frames = len(data)
            
            for start in range(0, n_frames - window_size + 1, stride):
                end = start + window_size
                windows.append(data[start:end])
                
                if labels_list is not None:
                    # Stage1: gait/non_gait ì´ì§„ ë¶„ë¥˜
                    window_label_seq = labels_list[idx][start:end]
                    # DS, SSR, SSL, double_support, single_support_left, single_support_rightì€ ëª¨ë‘ gaitë¡œ ë³€í™˜
                    binary_labels = ['gait' if l in ['DS', 'SSR', 'SSL', 'double_support', 'single_support_left', 'single_support_right'] else 'non_gait' 
                                   for l in window_label_seq]
                    # ìœˆë„ìš°ì˜ ëŒ€í‘œ ë¼ë²¨ (ë‹¤ìˆ˜ê²°)
                    unique, counts = np.unique(binary_labels, return_counts=True)
                    majority_label = unique[np.argmax(counts)]
                    window_labels.append(majority_label)
                else:
                    # non-walking ë°ì´í„°ëŠ” ëª¨ë‘ non_gait
                    window_labels.append('non_gait')
                    
        if windows:
            return np.array(windows), np.array(window_labels)
        else:
            return np.array([]).reshape(0, window_size, 6), np.array([])
    
    def create_stage2_windows(self, data_list, labels_list):
        """Stage2ìš© ìœˆë„ìš° ìƒì„± (15 frames, stride 1)"""
        window_size = 15
        stride = 1
        
        windows = []
        window_labels = []
        
        if not data_list:
            print("âš ï¸  Stage2 ìœˆë„ìš° ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return np.array([]).reshape(0, window_size, 6), np.array([])
        
        for idx, data in enumerate(data_list):
            n_frames = len(data)
            
            # ì²˜ìŒê³¼ ë 15í”„ë ˆì„ ì œì™¸
            for start in range(15, n_frames - window_size - 14, stride):
                end = start + window_size
                windows.append(data[start:end])
                
                # ê° í”„ë ˆì„ì˜ ë¼ë²¨ (DS, SSR, SSLë§Œ)
                frame_labels = []
                for frame_idx in range(start, end):
                    label = labels_list[idx][frame_idx]
                    if label in ['DS', 'SSR', 'SSL', 'double_support', 'single_support_left', 'single_support_right']:
                        # ë¼ë²¨ëª… ì •ê·œí™”
                        if label in ['double_support', 'DS']:
                            frame_labels.append('DS')
                        elif label in ['single_support_left', 'SSL']:
                            frame_labels.append('SSL')
                        elif label in ['single_support_right', 'SSR']:
                            frame_labels.append('SSR')
                        else:
                            frame_labels.append(label)
                    else:
                        frame_labels.append('DS')  # ê¸°ë³¸ê°’
                
                window_labels.append(frame_labels)
                
        if windows:
            return np.array(windows), np.array(window_labels)
        else:
            return np.array([]).reshape(0, window_size, 6), np.array([])
    
    def process_and_save(self):
        """ì „ì²´ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸš€ ë°ì´í„° ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        print("=" * 60)
        
        # 1. ë°ì´í„° ë¡œë“œ
        walking_data, walking_labels, walking_subjects = self.load_walking_data()
        non_walking_data, non_walking_subjects = self.load_non_walking_data()
        
        print(f"\nğŸ“Š ë°ì´í„° ë¡œë“œ ê²°ê³¼:")
        print(f"  ğŸš¶ Walking ë°ì´í„°: {len(walking_data)}ê°œ íŒŒì¼")
        print(f"  ğŸƒ Non-walking ë°ì´í„°: {len(non_walking_data)}ê°œ íŒŒì¼")
        
        # ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì˜¤ë¥˜
        if len(walking_data) == 0 and len(non_walking_data) == 0:
            raise ValueError("âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # 2. ë²„í„°ì›ŒìŠ¤ í•„í„° ì ìš©
        print(f"\nğŸ”§ ë²„í„°ì›ŒìŠ¤ í•„í„° ì ìš© ì¤‘...")
        if walking_data:
            walking_data = self.apply_filtering(walking_data)
            print(f"  âœ… Walking ë°ì´í„° í•„í„°ë§ ì™„ë£Œ")
        if non_walking_data:
            non_walking_data = self.apply_filtering(non_walking_data)
            print(f"  âœ… Non-walking ë°ì´í„° í•„í„°ë§ ì™„ë£Œ")
        
        # 3. Stage1 ë°ì´í„° ìƒì„±
        print(f"\nğŸ“¦ Stage1 ìœˆë„ìš° ìƒì„± ì¤‘...")
        walking_windows_s1, walking_labels_s1 = self.create_stage1_windows(walking_data, walking_labels)
        non_walking_windows_s1, non_walking_labels_s1 = self.create_stage1_windows(non_walking_data)
        
        print(f"  ğŸš¶ Walking windows: {walking_windows_s1.shape}")
        print(f"  ğŸƒ Non-walking windows: {non_walking_windows_s1.shape}")
        
        # ì „ì²´ Stage1 ë°ì´í„° ê²°í•© (ë¹ˆ ë°°ì—´ ì²˜ë¦¬)
        if walking_windows_s1.size > 0 and non_walking_windows_s1.size > 0:
            all_windows_s1 = np.vstack([walking_windows_s1, non_walking_windows_s1])
            all_labels_s1 = np.hstack([walking_labels_s1, non_walking_labels_s1])
        elif walking_windows_s1.size > 0:
            all_windows_s1 = walking_windows_s1
            all_labels_s1 = walking_labels_s1
        elif non_walking_windows_s1.size > 0:
            all_windows_s1 = non_walking_windows_s1
            all_labels_s1 = non_walking_labels_s1
        else:
            raise ValueError("âŒ ìƒì„±ëœ ìœˆë„ìš°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"  ğŸ“¦ ì „ì²´ Stage1 windows: {all_windows_s1.shape}")
        
        # 4. ìŠ¤ì¼€ì¼ë§ (Stage1)
        print(f"\nâš–ï¸  Stage1 ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì¤‘...")
        # Reshape for scaling
        n_samples, n_frames, n_features = all_windows_s1.shape
        all_windows_s1_reshaped = all_windows_s1.reshape(-1, n_features)
        
        # Fit and transform
        all_windows_s1_minmax = self.minmax_scaler.fit_transform(all_windows_s1_reshaped)
        all_windows_s1_standard = self.standard_scaler.fit_transform(all_windows_s1_reshaped)
        
        # Reshape back
        all_windows_s1_minmax = all_windows_s1_minmax.reshape(n_samples, n_frames, n_features)
        all_windows_s1_standard = all_windows_s1_standard.reshape(n_samples, n_frames, n_features)
        
        print(f"  âœ… ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: MinMax, Standard")
        
        # 5. Stage2 ë°ì´í„° ìƒì„± (walking dataë§Œ)
        print(f"\nğŸ“¦ Stage2 ìœˆë„ìš° ìƒì„± ì¤‘...")
        if walking_data:
            walking_windows_s2, walking_labels_s2 = self.create_stage2_windows(walking_data, walking_labels)
            print(f"  ğŸ“¦ Stage2 windows: {walking_windows_s2.shape}")
        else:
            walking_windows_s2 = np.array([]).reshape(0, 15, 6)
            walking_labels_s2 = np.array([])
            print(f"  âš ï¸  Walking ë°ì´í„°ê°€ ì—†ì–´ Stage2 ìœˆë„ìš° ìƒì„± ë¶ˆê°€")
        
        # 6. ì €ì¥
        save_dir = os.path.join(self.base_path, f"preprocessed_{self.timestamp}")
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘: {save_dir}")
        
        # Stage1 ë°ì´í„° ì €ì¥
        np.save(os.path.join(save_dir, "stage1_data_minmax.npy"), all_windows_s1_minmax)
        np.save(os.path.join(save_dir, "stage1_data_standard.npy"), all_windows_s1_standard)
        np.save(os.path.join(save_dir, "stage1_labels.npy"), all_labels_s1)
        
        # Stage2 ë°ì´í„° ì €ì¥
        if walking_windows_s2.size > 0:
            np.save(os.path.join(save_dir, "stage2_data.npy"), walking_windows_s2)
            np.save(os.path.join(save_dir, "stage2_labels.npy"), walking_labels_s2)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        with open(os.path.join(save_dir, "minmax_scaler.pkl"), 'wb') as f:
            pickle.dump(self.minmax_scaler, f)
        with open(os.path.join(save_dir, "standard_scaler.pkl"), 'wb') as f:
            pickle.dump(self.standard_scaler, f)
            
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'timestamp': self.timestamp,
            'n_walking_subjects': len(set(walking_subjects)) if walking_subjects else 0,
            'n_non_walking_subjects': len(set(non_walking_subjects)) if non_walking_subjects else 0,
            'stage1_shape': all_windows_s1_minmax.shape,
            'stage2_shape': walking_windows_s2.shape,
            'walking_subjects': list(set(walking_subjects)) if walking_subjects else [],
            'non_walking_subjects': list(set(non_walking_subjects)) if non_walking_subjects else [],
            'stage1_label_distribution': {label: int(count) for label, count in zip(*np.unique(all_labels_s1, return_counts=True))},
            'total_files_processed': {
                'walking': len(walking_data),
                'non_walking': len(non_walking_data)
            }
        }
        
        with open(os.path.join(save_dir, "metadata.pkl"), 'wb') as f:
            pickle.dump(metadata, f)
        
        # ë©”íƒ€ë°ì´í„°ë¥¼ JSONìœ¼ë¡œë„ ì €ì¥ (ê°€ë…ì„±ì„ ìœ„í•´)
        with open(os.path.join(save_dir, "metadata.json"), 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print("=" * 60)
        print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"  ğŸ“¦ Stage1 ë°ì´í„°: {all_windows_s1_minmax.shape}")
        print(f"  ğŸ“¦ Stage2 ë°ì´í„°: {walking_windows_s2.shape}")
        print(f"  ğŸ“‹ ë¼ë²¨ ë¶„í¬: {metadata['stage1_label_distribution']}")
        print(f"  ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {save_dir}")
        print("=" * 60)
        
        return save_dir

if __name__ == "__main__":
    preprocessor = GaitDataPreprocessor()
    save_path = preprocessor.process_and_save()
    print(f"ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")